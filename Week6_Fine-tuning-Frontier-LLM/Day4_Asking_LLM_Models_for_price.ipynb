{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "22b3e15c",
   "metadata": {},
   "source": [
    "### 2 important points:\n",
    "\n",
    "It's important to appreciate that we aren't Training the frontier models. We're only providing them with the Test dataset to see how they perform. They don't gain the benefit of the 400,000 training examples that we provided to the Traditional ML models.\n",
    "\n",
    "HAVING SAID THAT...\n",
    "\n",
    "It's entirely possible that in their monstrously large training data, they've already been exposed to all the products in the training AND the test set. So there could be test \"contamination\" here which gives them an unfair advantage. We should keep that in mind."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89daeb8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "\n",
    "import re\n",
    "import math\n",
    "import json\n",
    "import random\n",
    "import ollama\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pickle\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "347c8ff3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# moved our Tester into a separate package\n",
    "# call it with Tester.test(function_name, test_dataset)\n",
    "\n",
    "from items import Item\n",
    "from testing import Tester"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "696bd4ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's avoid curating all our data again! Load in the pickle files:\n",
    "\n",
    "with open('train_lite.pkl', 'rb') as file:\n",
    "    train = pickle.load(file)\n",
    "\n",
    "with open('test_lite.pkl', 'rb') as file:\n",
    "    test = pickle.load(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7422a221",
   "metadata": {},
   "source": [
    "# Before we look at the Frontier\n",
    "\n",
    "## There is one more model we could consider"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1157dfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write the test set to a CSV\n",
    "\n",
    "import csv\n",
    "with open('human_input.csv', 'w', encoding=\"utf-8\") as csvfile:\n",
    "    writer = csv.writer(csvfile)\n",
    "    for t in test[:250]:\n",
    "        writer.writerow([t.test_prompt(), 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b978e848",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read it back in\n",
    "\n",
    "# Of course this doesnt work for my case since ed predicted for his own \n",
    "# extra large dataset and mine is the lite version\n",
    "\n",
    "human_predictions = []\n",
    "with open('human_output.csv', 'r', encoding=\"utf-8\") as csvfile:\n",
    "    reader = csv.reader(csvfile)\n",
    "    for row in reader:\n",
    "        human_predictions.append(float(row[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2d9d99e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def human_pricer(item):\n",
    "    idx = test.index(item)\n",
    "    return human_predictions[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bab42aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "Tester.test(human_pricer, test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58390648",
   "metadata": {},
   "source": [
    "# Ed now gets into Frontier Models but of course I cant use them so will have to just try with the open-source ones, if I can."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e31b116f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def messages_for(item):\n",
    "    system_message = \"You estimate prices of items. Reply only with the price, no explanation\"\n",
    "    user_prompt = item.test_prompt().replace(\" to the nearest dollar\",\"\").replace(\"\\n\\nPrice is $\",\"\")\n",
    "    return [\n",
    "        {\"role\": \"system\", \"content\": system_message},\n",
    "        {\"role\": \"user\", \"content\": user_prompt},\n",
    "        {\"role\": \"assistant\", \"content\": \"Price is $\"}\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd1ceb40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try this out\n",
    "\n",
    "messages_for(test[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4926d675",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A utility function to extract the price from a string\n",
    "\n",
    "def get_price(s):\n",
    "    s = s.replace('$','').replace(',','')\n",
    "    match = re.search(r\"[-+]?\\d*\\.\\d+|\\d+\", s)\n",
    "    return float(match.group()) if match else 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfd2b646",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The function for ollama\n",
    "\n",
    "def ollama_call(item):\n",
    "    response = ollama.chat(\n",
    "        model=\"deepseek-v3.1:671b-cloud\", \n",
    "        messages=messages_for(item),\n",
    "        options={\n",
    "            \"num_predict\": 5 \n",
    "        }\n",
    "    )\n",
    "    reply = response.message.content\n",
    "    return get_price(reply)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d79e2fe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "ollama_call(test[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "367be99f",
   "metadata": {},
   "outputs": [],
   "source": [
    "Tester.test(ollama_call, test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
